{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e335f645",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa2a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print('All libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cda70",
   "metadata": {},
   "source": [
    "## 2. Generate Sample Dataset\n",
    "\n",
    "Since this is a portfolio project, we'll generate a realistic e-commerce dataset for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f08ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic e-commerce data\n",
    "n_records = 5000\n",
    "\n",
    "# Date range: 2019-2024\n",
    "date_start = pd.to_datetime('2019-01-01')\n",
    "date_end = pd.to_datetime('2024-12-31')\n",
    "dates = pd.date_range(start=date_start, end=date_end, periods=n_records)\n",
    "\n",
    "# Create dataset\n",
    "data = {\n",
    "    'order_id': range(1000, 1000 + n_records),\n",
    "    'customer_id': np.random.randint(1000, 2000, n_records),\n",
    "    'order_date': dates,\n",
    "    'category': np.random.choice(['Electronics', 'Home & Garden', 'Fashion', 'Books', 'Sports'], n_records, p=[0.35, 0.28, 0.20, 0.12, 0.05]),\n",
    "    'quantity': np.random.randint(1, 10, n_records),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], n_records),\n",
    "    'customer_segment': np.random.choice(['Regular', 'Premium', 'New'], n_records, p=[0.60, 0.25, 0.15])\n",
    "}\n",
    "\n",
    "# Add sales with some correlation to quantity and category\n",
    "category_prices = {'Electronics': 300, 'Home & Garden': 150, 'Fashion': 80, 'Books': 25, 'Sports': 120}\n",
    "data['sales'] = data['quantity'] * data['category'].map(category_prices) + np.random.normal(0, 50, n_records)\n",
    "data['sales'] = data['sales'].clip(lower=0)  # Ensure non-negative\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(f'Dataset generated with {len(df)} records')\n",
    "print(f'Date range: {df[\"order_date\"].min().date()} to {df[\"order_date\"].max().date()}')\n",
    "print(f'\\nFirst few rows:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3af88",
   "metadata": {},
   "source": [
    "## 3. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55891f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print('=' * 60)\n",
    "print('DATASET OVERVIEW')\n",
    "print('=' * 60)\n",
    "\n",
    "print(f'\\nDataset Shape: {df.shape}')\n",
    "print(f'\\nColumn Names and Types:')\n",
    "print(df.dtypes)\n",
    "print(f'\\nBasic Statistics:')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print('\\n' + '=' * 60)\n",
    "print('MISSING VALUES ANALYSIS')\n",
    "print('=' * 60)\n",
    "\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "\n",
    "print('\\n', missing_df[missing_df['Missing_Count'] > 0])\n",
    "print('No missing values found!' if missing_df['Missing_Count'].sum() == 0 else '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da3d1c",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aace42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Ensure correct data types\n",
    "df_clean['order_date'] = pd.to_datetime(df_clean['order_date'])\n",
    "\n",
    "# Remove duplicates\n",
    "initial_rows = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "duplicates_removed = initial_rows - len(df_clean)\n",
    "print(f'Duplicates removed: {duplicates_removed}')\n",
    "\n",
    "# Handle outliers using IQR method\n",
    "Q1 = df_clean['sales'].quantile(0.25)\n",
    "Q3 = df_clean['sales'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 3 * IQR\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "outliers = df_clean[(df_clean['sales'] < lower_bound) | (df_clean['sales'] > upper_bound)]\n",
    "print(f'Outliers detected: {len(outliers)}')\n",
    "df_clean = df_clean[(df_clean['sales'] >= lower_bound) & (df_clean['sales'] <= upper_bound)]\n",
    "\n",
    "# Extract time features\n",
    "df_clean['year'] = df_clean['order_date'].dt.year\n",
    "df_clean['month'] = df_clean['order_date'].dt.month\n",
    "df_clean['quarter'] = df_clean['order_date'].dt.quarter\n",
    "df_clean['day_of_week'] = df_clean['order_date'].dt.day_name()\n",
    "df_clean['is_weekend'] = df_clean['order_date'].dt.dayofweek.isin([5, 6]).astype(int)\n",
    "\n",
    "# Create derived features\n",
    "df_clean['price_per_unit'] = df_clean['sales'] / df_clean['quantity']\n",
    "\n",
    "print(f'\\nData cleaning completed!')\n",
    "print(f'Final dataset shape: {df_clean.shape}')\n",
    "print(f'\\nNew features created: year, month, quarter, day_of_week, is_weekend, price_per_unit')\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a33b28d",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print('=' * 60)\n",
    "print('DESCRIPTIVE STATISTICS')\n",
    "print('=' * 60)\n",
    "print('\\nSales Statistics:')\n",
    "print(f'  Total Revenue: ${df_clean[\"sales\"].sum():,.2f}')\n",
    "print(f'  Average Order Value: ${df_clean[\"sales\"].mean():,.2f}')\n",
    "print(f'  Median Order Value: ${df_clean[\"sales\"].median():,.2f}')\n",
    "print(f'  Standard Deviation: ${df_clean[\"sales\"].std():,.2f}')\n",
    "print(f'  Min Sale: ${df_clean[\"sales\"].min():,.2f}')\n",
    "print(f'  Max Sale: ${df_clean[\"sales\"].max():,.2f}')\n",
    "\n",
    "print('\\nCustomer Statistics:')\n",
    "print(f'  Total Unique Customers: {df_clean[\"customer_id\"].nunique()}')\n",
    "print(f'  Total Orders: {len(df_clean)}')\n",
    "print(f'  Average Orders per Customer: {len(df_clean) / df_clean[\"customer_id\"].nunique():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category analysis\n",
    "print('\\n' + '=' * 60)\n",
    "print('SALES BY CATEGORY')\n",
    "print('=' * 60)\n",
    "\n",
    "category_analysis = df_clean.groupby('category').agg({\n",
    "    'sales': ['sum', 'mean', 'count']\n",
    "}).round(2)\n",
    "\n",
    "category_analysis.columns = ['Total Sales', 'Avg Sale', 'Count']\n",
    "category_analysis['Percentage'] = (category_analysis['Total Sales'] / category_analysis['Total Sales'].sum() * 100).round(2)\n",
    "category_analysis = category_analysis.sort_values('Total Sales', ascending=False)\n",
    "\n",
    "print('\\n', category_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76caeaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional analysis\n",
    "print('\\n' + '=' * 60)\n",
    "print('SALES BY REGION')\n",
    "print('=' * 60)\n",
    "\n",
    "region_analysis = df_clean.groupby('region').agg({\n",
    "    'sales': ['sum', 'mean', 'count']\n",
    "}).round(2)\n",
    "\n",
    "region_analysis.columns = ['Total Sales', 'Avg Sale', 'Count']\n",
    "region_analysis['Percentage'] = (region_analysis['Total Sales'] / region_analysis['Total Sales'].sum() * 100).round(2)\n",
    "region_analysis = region_analysis.sort_values('Total Sales', ascending=False)\n",
    "\n",
    "print('\\n', region_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800dc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer segment analysis\n",
    "print('\\n' + '=' * 60)\n",
    "print('SALES BY CUSTOMER SEGMENT')\n",
    "print('=' * 60)\n",
    "\n",
    "segment_analysis = df_clean.groupby('customer_segment').agg({\n",
    "    'sales': ['sum', 'mean', 'count'],\n",
    "    'customer_id': 'nunique'\n",
    "}).round(2)\n",
    "\n",
    "segment_analysis.columns = ['Total Sales', 'Avg Sale', 'Orders', 'Customers']\n",
    "segment_analysis['Avg Orders per Customer'] = (segment_analysis['Orders'] / segment_analysis['Customers']).round(2)\n",
    "segment_analysis = segment_analysis.sort_values('Total Sales', ascending=False)\n",
    "\n",
    "print('\\n', segment_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7f724",
   "metadata": {},
   "source": [
    "## 6. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49338162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of sales\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histogram of sales\n",
    "axes[0, 0].hist(df_clean['sales'], bins=50, edgecolor='black', color='steelblue', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of Sales Amount', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Sales ($)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot of sales\n",
    "axes[0, 1].boxplot(df_clean['sales'])\n",
    "axes[0, 1].set_title('Sales Amount - Box Plot', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Sales ($)')\n",
    "\n",
    "# Distribution of quantity\n",
    "axes[1, 0].hist(df_clean['quantity'], bins=10, edgecolor='black', color='lightcoral', alpha=0.7)\n",
    "axes[1, 0].set_title('Distribution of Quantity', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Quantity')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot of quantity\n",
    "axes[1, 1].boxplot(df_clean['quantity'])\n",
    "axes[1, 1].set_title('Quantity - Box Plot', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Quantity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Sales Distribution Statistics:')\n",
    "print(f'  Skewness: {stats.skew(df_clean[\"sales\"]):.3f}')\n",
    "print(f'  Kurtosis: {stats.kurtosis(df_clean[\"sales\"]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by category and region\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar chart - Sales by Category\n",
    "category_sales = df_clean.groupby('category')['sales'].sum().sort_values(ascending=False)\n",
    "axes[0].bar(category_sales.index, category_sales.values, color='steelblue', alpha=0.8, edgecolor='black')\n",
    "axes[0].set_title('Total Sales by Category', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Category')\n",
    "axes[0].set_ylabel('Sales ($)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(category_sales.values):\n",
    "    axes[0].text(i, v + 5000, f'${v:,.0f}', ha='center', va='bottom')\n",
    "\n",
    "# Bar chart - Sales by Region\n",
    "region_sales = df_clean.groupby('region')['sales'].sum().sort_values(ascending=False)\n",
    "axes[1].bar(region_sales.index, region_sales.values, color='lightcoral', alpha=0.8, edgecolor='black')\n",
    "axes[1].set_title('Total Sales by Region', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Region')\n",
    "axes[1].set_ylabel('Sales ($)')\n",
    "for i, v in enumerate(region_sales.values):\n",
    "    axes[1].text(i, v + 5000, f'${v:,.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a748775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly sales trend\n",
    "monthly_sales = df_clean.groupby(df_clean['order_date'].dt.to_period('M'))['sales'].sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "monthly_sales.plot(kind='line', marker='o', color='steelblue', linewidth=2, markersize=6, ax=ax)\n",
    "ax.set_title('Monthly Sales Trend (2019-2024)', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Sales ($)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nMonthly Sales Summary:')\n",
    "print(f'  Average Monthly Sales: ${monthly_sales.mean():,.2f}')\n",
    "print(f'  Max Monthly Sales: ${monthly_sales.max():,.2f}')\n",
    "print(f'  Min Monthly Sales: ${monthly_sales.min():,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category and Region interaction\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "category_region = df_clean.groupby(['category', 'region'])['sales'].sum().unstack()\n",
    "category_region.plot(kind='bar', ax=ax, width=0.8, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "ax.set_title('Sales by Category and Region', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Category')\n",
    "ax.set_ylabel('Sales ($)')\n",
    "ax.legend(title='Region')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b482d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = df_clean[numeric_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, fmt='.2f', ax=ax, cbar_kws={'label': 'Correlation'})\n",
    "ax.set_title('Correlation Matrix of Numeric Variables', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nKey Correlations with Sales:')\n",
    "correlations_with_sales = correlation_matrix['sales'].sort_values(ascending=False)\n",
    "print(correlations_with_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930b664",
   "metadata": {},
   "source": [
    "## 7. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM (Recency, Frequency, Monetary) Analysis\n",
    "print('=' * 60)\n",
    "print('RFM ANALYSIS')\n",
    "print('=' * 60)\n",
    "\n",
    "# Calculate RFM metrics\n",
    "current_date = df_clean['order_date'].max()\n",
    "\n",
    "rfm = df_clean.groupby('customer_id').agg({\n",
    "    'order_date': lambda x: (current_date - x.max()).days,  # Recency\n",
    "    'customer_id': 'count',  # Frequency\n",
    "    'sales': 'sum'  # Monetary\n",
    "})\n",
    "\n",
    "rfm.columns = ['Recency', 'Frequency', 'Monetary']\n",
    "rfm = rfm[rfm['Monetary'] > 0]\n",
    "\n",
    "print(f'\\nRFM Statistics:')\n",
    "print(rfm.describe().round(2))\n",
    "\n",
    "# Segment customers\n",
    "rfm['R_Quartile'] = pd.qcut(rfm['Recency'], 4, labels=['1', '2', '3', '4'], duplicates='drop')\n",
    "rfm['F_Quartile'] = pd.qcut(rfm['Frequency'].rank(method='first'), 4, labels=['4', '3', '2', '1'], duplicates='drop')\n",
    "rfm['M_Quartile'] = pd.qcut(rfm['Monetary'], 4, labels=['4', '3', '2', '1'], duplicates='drop')\n",
    "\n",
    "rfm['RFM_Segment'] = rfm['R_Quartile'].astype(str) + rfm['F_Quartile'].astype(str) + rfm['M_Quartile'].astype(str)\n",
    "\n",
    "print(f'\\nCustomer Segments: {rfm[\"RFM_Segment\"].nunique()} unique segments')\n",
    "print(f'\\nTop 10 RFM Segments:')\n",
    "print(rfm['RFM_Segment'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac09041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Lifetime Value\n",
    "print('\\n' + '=' * 60)\n",
    "print('CUSTOMER LIFETIME VALUE (CLV) ANALYSIS')\n",
    "print('=' * 60)\n",
    "\n",
    "clv = rfm[['Monetary', 'Frequency']].copy()\n",
    "clv['Avg_Order_Value'] = clv['Monetary'] / clv['Frequency']\n",
    "clv = clv.sort_values('Monetary', ascending=False)\n",
    "\n",
    "print(f'\\nCLV Statistics:')\n",
    "print(clv.describe().round(2))\n",
    "\n",
    "print(f'\\nTop 10 Customers by CLV:')\n",
    "print(clv.head(10).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec56cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RFM and CLV\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Recency distribution\n",
    "axes[0, 0].hist(rfm['Recency'], bins=30, edgecolor='black', color='steelblue', alpha=0.7)\n",
    "axes[0, 0].set_title('Recency Distribution', fontsize=11, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Days Since Last Purchase')\n",
    "axes[0, 0].set_ylabel('Number of Customers')\n",
    "\n",
    "# Frequency distribution\n",
    "axes[0, 1].hist(rfm['Frequency'], bins=20, edgecolor='black', color='lightcoral', alpha=0.7)\n",
    "axes[0, 1].set_title('Frequency Distribution', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Number of Purchases')\n",
    "axes[0, 1].set_ylabel('Number of Customers')\n",
    "\n",
    "# Monetary distribution\n",
    "axes[1, 0].hist(rfm['Monetary'], bins=30, edgecolor='black', color='lightgreen', alpha=0.7)\n",
    "axes[1, 0].set_title('Monetary Distribution', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Total Spending ($)')\n",
    "axes[1, 0].set_ylabel('Number of Customers')\n",
    "\n",
    "# Frequency vs Monetary (Scatter)\n",
    "scatter = axes[1, 1].scatter(rfm['Frequency'], rfm['Monetary'], alpha=0.6, c=rfm['Recency'], \n",
    "                             cmap='RdYlBu_r', s=100, edgecolor='black', linewidth=0.5)\n",
    "axes[1, 1].set_title('Frequency vs Monetary Value', fontsize=11, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Purchase Frequency')\n",
    "axes[1, 1].set_ylabel('Total Spending ($)')\n",
    "cbar = plt.colorbar(scatter, ax=axes[1, 1])\n",
    "cbar.set_label('Recency (Days)', rotation=270, labelpad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3385f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis Testing: Are sales different across regions?\n",
    "from scipy.stats import f_oneway, chi2_contingency\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('HYPOTHESIS TESTING')\n",
    "print('=' * 60)\n",
    "\n",
    "# ANOVA test: Sales across regions\n",
    "north_sales = df_clean[df_clean['region'] == 'North']['sales']\n",
    "south_sales = df_clean[df_clean['region'] == 'South']['sales']\n",
    "east_sales = df_clean[df_clean['region'] == 'East']['sales']\n",
    "west_sales = df_clean[df_clean['region'] == 'West']['sales']\n",
    "\n",
    "f_stat, p_value = f_oneway(north_sales, south_sales, east_sales, west_sales)\n",
    "\n",
    "print(f'\\nANOVA Test: Sales across Regions')\n",
    "print(f'  Null Hypothesis: Mean sales are equal across all regions')\n",
    "print(f'  F-Statistic: {f_stat:.4f}')\n",
    "print(f'  P-Value: {p_value:.6f}')\n",
    "print(f'  Result: {\"Reject null hypothesis\" if p_value < 0.05 else \"Fail to reject null hypothesis\"}')\n",
    "\n",
    "# Chi-square test: Category independence from Region\n",
    "contingency_table = pd.crosstab(df_clean['category'], df_clean['region'])\n",
    "chi2, p_val, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f'\\nChi-Square Test: Category Independence from Region')\n",
    "print(f'  Null Hypothesis: Category and Region are independent')\n",
    "print(f'  Chi-Square Statistic: {chi2:.4f}')\n",
    "print(f'  P-Value: {p_val:.6f}')\n",
    "print(f'  Result: {\"Reject null hypothesis\" if p_val < 0.05 else \"Fail to reject null hypothesis\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4546b",
   "metadata": {},
   "source": [
    "## 8. Business Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4865f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('KEY BUSINESS INSIGHTS & RECOMMENDATIONS')\n",
    "print('=' * 70)\n",
    "\n",
    "# Calculate key metrics\n",
    "total_revenue = df_clean['sales'].sum()\n",
    "total_customers = df_clean['customer_id'].nunique()\n",
    "avg_order_value = df_clean['sales'].mean()\n",
    "total_orders = len(df_clean)\n",
    "orders_per_customer = total_orders / total_customers\n",
    "\n",
    "# Top performing categories\n",
    "top_category = df_clean.groupby('category')['sales'].sum().idxmax()\n",
    "top_category_sales = df_clean[df_clean['category'] == top_category]['sales'].sum()\n",
    "top_category_pct = (top_category_sales / total_revenue) * 100\n",
    "\n",
    "# Best performing region\n",
    "top_region = df_clean.groupby('region')['sales'].sum().idxmax()\n",
    "top_region_sales = df_clean[df_clean['region'] == top_region]['sales'].sum()\n",
    "top_region_pct = (top_region_sales / total_revenue) * 100\n",
    "\n",
    "# Customer segment insights\n",
    "premium_pct = (df_clean[df_clean['customer_segment'] == 'Premium']['sales'].sum() / total_revenue) * 100\n",
    "\n",
    "print(f'\\n1. REVENUE & SALES METRICS')\n",
    "print(f'   • Total Revenue: ${total_revenue:,.2f}')\n",
    "print(f'   • Total Unique Customers: {total_customers:,}')\n",
    "print(f'   • Total Orders: {total_orders:,}')\n",
    "print(f'   • Average Order Value: ${avg_order_value:.2f}')\n",
    "print(f'   • Orders per Customer: {orders_per_customer:.2f}')\n",
    "\n",
    "print(f'\\n2. PRODUCT PERFORMANCE')\n",
    "print(f'   • Top Category: {top_category} ({top_category_pct:.1f}% of revenue)')\n",
    "print(f'   • Top Category Revenue: ${top_category_sales:,.2f}')\n",
    "\n",
    "print(f'\\n3. GEOGRAPHIC INSIGHTS')\n",
    "print(f'   • Best Performing Region: {top_region} ({top_region_pct:.1f}% of revenue)')\n",
    "print(f'   • Regional Revenue: ${top_region_sales:,.2f}')\n",
    "\n",
    "print(f'\\n4. CUSTOMER SEGMENTATION')\n",
    "print(f'   • Premium Customers Contribution: {premium_pct:.1f}% of revenue')\n",
    "segment_breakdown = df_clean.groupby('customer_segment')['customer_id'].nunique()\n",
    "for segment in segment_breakdown.index:\n",
    "    pct = (segment_breakdown[segment] / total_customers) * 100\n",
    "    print(f'     - {segment}: {segment_breakdown[segment]} customers ({pct:.1f}%)')\n",
    "\n",
    "print(f'\\n5. TREND ANALYSIS')\n",
    "yearly_sales = df_clean.groupby('year')['sales'].sum()\n",
    "growth_rate = ((yearly_sales.iloc[-1] - yearly_sales.iloc[-2]) / yearly_sales.iloc[-2]) * 100\n",
    "print(f'   • Latest Year-over-Year Growth: {growth_rate:.1f}%')\n",
    "print(f'   • Strongest Month: {df_clean[df_clean['month'] == df_clean.groupby('month')['sales'].sum().idxmax()]['month'].iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11604c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 70)\n",
    "print('STRATEGIC RECOMMENDATIONS')\n",
    "print('=' * 70)\n",
    "\n",
    "recommendations = [\n",
    "    {\n",
    "        'title': '1. FOCUS ON HIGH-VALUE CUSTOMER SEGMENTS',\n",
    "        'points': [\n",
    "            f'   • Premium customers represent {premium_pct:.1f}% of revenue with only {segment_breakdown[\"Premium\"] / total_customers * 100:.1f}% of customer base',\n",
    "            '   • Implement VIP loyalty programs for premium customers',\n",
    "            '   • Offer exclusive products and early access to new releases',\n",
    "            '   • Consider personalized customer service for high-value accounts'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'title': '2. OPTIMIZE PRODUCT CATEGORY STRATEGY',\n",
    "        'points': [\n",
    "            f'   • {top_category} dominates with {top_category_pct:.1f}% of revenue',\n",
    "            '   • Invest in marketing campaigns for underperforming categories',\n",
    "            '   • Bundle slow-moving categories with bestsellers',\n",
    "            '   • Expand inventory for high-margin products in {top_category}'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'title': '3. REGIONAL EXPANSION OPPORTUNITY',\n",
    "        'points': [\n",
    "            f'   • {top_region} region performs best ({top_region_pct:.1f}% of revenue)',\n",
    "            '   • Identify growth potential in underperforming regions',\n",
    "            '   • Tailor regional marketing strategies based on category preferences',\n",
    "            '   • Consider regional shipping optimization for lower-performing areas'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'title': '4. CUSTOMER RETENTION FOCUS',\n",
    "        'points': [\n",
    "            f'   • Average customer purchases only {orders_per_customer:.2f} times',\n",
    "            '   • Implement email marketing and follow-up campaigns',\n",
    "            '   • Create loyalty rewards program for repeat customers',\n",
    "            '   • Target inactive customers with win-back campaigns'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'title': '5. DATA-DRIVEN INVENTORY MANAGEMENT',\n",
    "        'points': [\n",
    "            '   • Use forecasting models to predict demand by category and region',\n",
    "            '   • Implement dynamic pricing strategies based on demand patterns',\n",
    "            '   • Monitor inventory turnover rates by product category',\n",
    "            '   • Reduce stockouts for high-demand products during peak seasons'\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(f'\\n{rec[\"title\"]}')\n",
    "    for point in rec['points']:\n",
    "        print(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a45b6",
   "metadata": {},
   "source": [
    "## 9. Summary & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary report\n",
    "summary_stats = {\n",
    "    'Metric': [\n",
    "        'Total Revenue',\n",
    "        'Total Orders',\n",
    "        'Unique Customers',\n",
    "        'Avg Order Value',\n",
    "        'Orders per Customer',\n",
    "        'Date Range',\n",
    "        'Top Category',\n",
    "        'Top Region'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f'${total_revenue:,.2f}',\n",
    "        f'{total_orders:,}',\n",
    "        f'{total_customers:,}',\n",
    "        f'${avg_order_value:.2f}',\n",
    "        f'{orders_per_customer:.2f}',\n",
    "        f'{df_clean[\"order_date\"].min().date()} to {df_clean[\"order_date\"].max().date()}',\n",
    "        top_category,\n",
    "        top_region\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('ANALYSIS SUMMARY')\n",
    "print('=' * 70)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data\n",
    "export_path = '../data/processed/cleaned_data.csv'\n",
    "df_clean.to_csv(export_path, index=False)\n",
    "print(f'✓ Cleaned dataset exported to: {export_path}')\n",
    "\n",
    "# Export summary statistics\n",
    "summary_df.to_csv('../data/processed/summary_statistics.csv', index=False)\n",
    "print(f'✓ Summary statistics exported to: ../data/processed/summary_statistics.csv')\n",
    "\n",
    "# Export RFM analysis\n",
    "rfm.to_csv('../data/processed/rfm_analysis.csv')\n",
    "print(f'✓ RFM analysis exported to: ../data/processed/rfm_analysis.csv')\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('ANALYSIS COMPLETE')\n",
    "print('=' * 70)\n",
    "print('\\nAll visualizations, cleaned data, and analysis results have been saved.')\n",
    "print('\\nFiles generated:')\n",
    "print('  • Cleaned Dataset: data/processed/cleaned_data.csv')\n",
    "print('  • Summary Statistics: data/processed/summary_statistics.csv')\n",
    "print('  • RFM Analysis: data/processed/rfm_analysis.csv')\n",
    "print('\\nNext Steps:')\n",
    "print('  1. Review visualizations for presentations')\n",
    "print('  2. Share insights with stakeholders')\n",
    "print('  3. Implement recommendations for business optimization')\n",
    "print('  4. Monitor KPIs monthly for performance tracking')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
